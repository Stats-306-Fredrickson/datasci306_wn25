---
title: "Stats 306: Lecture 6"
subtitle: "Grouping and Summaries"
author: "Mark Fredrickson"
output: 
  learnr::tutorial:
    progressive: true
    css: css/lecture.css
runtime: shiny_prerendered
---


```{r setup, include=FALSE}
library(learnr)
library(tidyverse)
library(lubridate) # install.packages("lubridate") if you don't have this
aatemp <- read_csv("data/ann_arbor_weather.csv.gz")
```

## TODO: Review on filter/select

## Review: `mutate`

* `mutate`: Takes a table and returns a new table with columns added and/or subtracted
* Give us access to columns of `tbl` without having to write `tbl$column_name`
* `mutate(d, new_col = f(x, y), new_col2 = new_col1 + 1, old_col = NULL)`
* `if_else(cond, true, false)` (all are vectors of same length or single values): used `TRUE` and `FALSE` values in `cond` to pick value from `true` and `false` (respectively)
* Can use functions that summarize, e.g., `mutate(d, x_centered = x - mean(x))`

## Temperature data for Ann Arbor, MI

```{r}
# to run this line from the console, use `setwd("lectures")` first
aatemp
```

## `mutate` to add a column

```{r}
aatemp_cel <- mutate(aatemp, TMAX_celsius = (TMAX - 32) * 5/9) |>
  select(TMAX, TMAX_celsius)
```

## `summary` and `summarize`

R has a built in a function called `summary` that gives a distilled look at a table:
```{r}
aat_4col <- select(aatemp, c("STATION", "DATE", "TMAX", "SNOW"))
summary(aat_4col)
```

The `summarize` function is from `dplyr` (part of `tidyverse`) and allows computing arbitrary summaries.

```{r}
summarize(aat_4col, avg_TMAX = mean(TMAX), days_of_snow = sum(!is.na(SNOW)))
```

## Summarize variations: `_if`, `_at`, `_all`

```{r}
select(aatemp, where(is.numeric)) |> summarize_all(mean, na.rm = TRUE)
summarize_if(aatemp, is.numeric, var, na.rm = TRUE)
summarize_at(aatemp, c("TMAX", "TMIN"), c(maximum = max, minimum = min))
```

## Exercise

For the `mpg` data set, compute the mean `hwy` mileage and median `cty` mileage. Compute the variance of the ratio of `hwy` to `city`.
```{r summary, exercise = TRUE}

```

## Grouping

Often we want to break data out across categories and compute summaries within each.

```{r}
group_by(aatemp, year(DATE)) |> summarize(avg_TMAX = mean(TMAX), days_of_snow = sum(!is.na(SNOW)))
```

## Inspecting group data

```{r}

aat_year <- group_by(aatemp, year(DATE))
nrow(aat_year) == nrow(aatemp)
colnames(aat_year)[18]
group_vars(aat_year)
```

## Grouping by year and month
```{r}
aat_year_month <- group_by(aat_year, month(DATE), .add = TRUE)
group_vars(aat_year_month)
```

```{r}
aat_year_month <- group_by(aatemp, year(DATE), month(DATE))
group_vars(aat_year_month)
```

## Aggregating up with `summarize` function

```{r}
summarize(aat_year_month, avg_TMAX = mean(TMAX)) |>
  ggplot(aes(x = `year(DATE)` + `month(DATE)` / 12, avg_TMAX)) +
  geom_line()

```

## Aggregating up two levels

```{r}
summarize(aat_year_month, monthly_avg_tmax = mean(TMAX)) |>
  summarize(yearly_median_monthy_mean = median(monthly_avg_tmax))
```

## Exercise

Using the `mpg` data set, find the manufacturer (`manufacturer`) with the highest mean highway efficiency (`hwy`)
```{r manufacturer-hwy, exercise = TRUE}

```

## Arranging output

Sometimes we want to choose the ordering of rows in a table. I don't use this a lot for raw data, but it can be quite helpful for summaries:

```{r}
group_by(aatemp, year(DATE)) |> 
  summarize(yearly_maxT = max(TMAX)) |> 
  arrange(yearly_maxT)
```

## Descending order, multiple columns


```{r}
group_by(aatemp, year(DATE)) |> 
  summarize(yearly_maxT = max(TMAX), yearly_minT = min(TMAX)) |> 
  arrange(desc(yearly_maxT), yearly_minT)
```

## Exercise

Group by both `manufacturer` and `class`. What manufacturer has the highest `cty` efficiency in the sense of the median of mean `cty` within class?

```{r manufacturer-hwy, exercise = TRUE}
```


## Grouping by year
```{r}
aat_year <- group_by(aatemp, year(DATE))
summarize(aat_year, median(TMAX - TMIN, na.rm = TRUE))
```
## Useful functions for summaries

* Seen before: `mean`, `median`, `sd`, `min`, `max`
* Other common statistical measures: `quantile`, `IQR`
* For boolean/logical columns: `any` and `all` ("or" and "and" across vectors)
* The functions `n` and a `n_distinct` count units and distinct values

## Some more summaries

```{r}
summarize(aat_year, n(), n_distinct(TMAX), any(SNOW > 10))
```

## Centered temperature

```{r}
mutate(aatemp, TMAX_centered = TMAX - mean(TMAX)) |>
 ggplot(aes(y = TMAX_centered, x = factor(quarter(DATE)))) +
    geom_violin() 
```

## `mutate` and `group_by`

Observe some care when using `mutate` on grouped tables:

```{r}
group_by(aatemp, quarter(DATE)) |>
  mutate(TMAX_centered = TMAX - mean(TMAX)) |>
  ggplot(aes(y = TMAX_centered, x = factor(`quarter(DATE)`))) +
    geom_violin()
```

## Normalizing by monthly averages?

Let's center each observation by it's monthly average that we can understand if
it was unusual for that time of year.

```{r}
aat_month_centered <- group_by(aatemp, month(DATE)) |>
  mutate(TMAX_centered = TMAX - mean(TMAX, na.rm = TRUE)) # mean computed over months
## verify as the variance should be pr
summarize(aat_month_centered, var(TMAX_centered), sum(TMAX_centered^2) / (n() - 1)) |>
  head(3)
```

## Unusual months continued: conversion to ranks

*Ranks* are a useful robust replacement for values that are less susceptible to outliers. Let's rank days by how far they were from their monthly mean.

**Danger**: mutate will operate within months!

```{r}
mutate(aat_month_centered, r = rank(TMAX_centered)) |> 
  summarize(min(r), max(r))
```

## Ungrouping to fix

We need to drop the grouping values so that we can rank across all days.

```{r}
ungroup(aat_month_centered) |> 
  mutate(aat_month_centered, r = rank(TMAX_centered)) |>
  summarize(min(r), max(r))
```

## Average rank within years

Now that we can rank across all years and months, what year had the highest
average ranks?

```{r}
ungroup(aat_month_centered) |> 
  mutate(aat_month_centered, r = rank(TMAX_centered)) |>
  group_by(year(DATE)) |>
  summarize(mean(r)) |>
  arrange(desc(`mean(r)`))
```

## Exercise

Let's put it all together using the `mpg` data set.

>* Get a list of manufacturers that produce cars in at least 2 different classes. (Recall `n_distinct` function)
>* Using that list, subset the `mpg` data to just those manufactures
>* Rescale the highway efficiency variable into Z-scores (using the common mean across all manufacturers)
>* Group the observations by manufacturer. Which one has the smallest variance in `cty` efficiency?

You may want to use `%in%`:
```{r}
c("Hi", "Low", "Low", "Medium") %in% c("Medium", "High")
```

```{r lastex, exercise = TRUE}

```

```{r lastex-solution}
at_least_2 <- group_by(mpg, manufacturer) |> 
  summarize(per_class = n_distinct(class)) |>
  filter(per_class > 1)

at_least_2

filter(mpg, manufacturer %in% at_least_2$manufacturer) |>
  mutate(cty_z = scale(cty)) |>
  group_by(manufacturer) |>
  summarize(v = var(cty_z)) |>
  arrange(v)
```

## Other R functions

Most other R functions do not recognize grouping:

```{r}
mean(aatemp$TMAX, na.rm = TRUE)
mean(aat_year$TMAX)
summarize(aat_year, mean(TMAX))
```


